# ü§ñ Digital Twin - Telegram Bot con YAML (Forma oficial CrewAI 2025)
# Usando la estructura recomendada: CrewBase + YAML configs

import os
import asyncio
from typing import Dict, Any
import logging

# Configurar logging
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

print("üîç INICIANDO IMPORTS...")

try:
    from telegram import Update
    from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
    print("‚úÖ Telegram importado")
except Exception as e:
    print(f"‚ùå Error Telegram: {e}")
    exit(1)

print("‚úÖ TODOS LOS IMPORTS OK")

# Configuration
TELEGRAM_TOKEN = os.getenv('TELEGRAM_TOKEN', '')
DEEPSEEK_API_KEY = os.getenv('DEEPSEEK_API_KEY', '')
DEEPSEEK_BASE_URL = os.getenv('DEEPSEEK_BASE_URL', 'https://api.deepseek.com/v1')

print(f"üîë TELEGRAM_TOKEN: {'‚úÖ OK' if TELEGRAM_TOKEN else '‚ùå FALTA'}")
print(f"üîë DEEPSEEK_API_KEY: {'‚úÖ OK' if DEEPSEEK_API_KEY else '‚ùå FALTA'}")


class SimpleDigitalTwin:
    """ü§ñ Digital Twin usando YAML configs (forma oficial CrewAI 2025)"""
    
    def __init__(self):
        print("ü§ñ Inicializando Digital Twin...")
        self.cv_data = self.load_cv_data()
        self.use_ai = False
        
        # Solo intentar AI si hay API key
        if DEEPSEEK_API_KEY:
            try:
                self.setup_ai()
            except Exception as e:
                print(f"‚ö†Ô∏è AI fall√≥, modo simple: {e}")
        
        print("‚úÖ Digital Twin listo")
    
    def load_cv_data(self) -> Dict[str, Any]:
        """Carga CV desde env vars"""
        return {
            "name": os.getenv('CV_NAME', 'Norbert Rodr√≠guez Sagarra'),
            "title": os.getenv('CV_TITLE', 'Senior AI Engineer & Project Manager'),
            "location": os.getenv('CV_LOCATION', 'Barcelona, Espa√±a'),
            "bio": os.getenv('CV_BIO', 'Experto en IA, datos y desarrollo de soluciones innovadoras'),
            "skills": os.getenv('CV_SKILLS', 'Python,AI,LangGraph,CrewAI,FastAPI,AWS').split(','),
            "availability": os.getenv('CV_AVAILABILITY', 'Disponible para proyectos de IA y consultor√≠a'),
            "experience": [
                {
                    "company": os.getenv('CV_EXP1_COMPANY', 'VEOLIA-AGBAR-SYNECTIC'),
                    "role": os.getenv('CV_EXP1_ROLE', 'Senior AI Engineer'),
                    "years": os.getenv('CV_EXP1_YEARS', '2021-2024'),
                    "highlights": os.getenv('CV_EXP1_HIGHLIGHTS', 'Sistemas IA empresariales para 50k+ usuarios')
                },
                {
                    "company": os.getenv('CV_EXP2_COMPANY', 'IBM Collaborative Projects'),
                    "role": os.getenv('CV_EXP2_ROLE', 'AI Solutions Architect'),
                    "years": os.getenv('CV_EXP2_YEARS', '2017-2022'),
                    "highlights": os.getenv('CV_EXP2_HIGHLIGHTS', 'Liderazgo de proyectos IA con Watson')
                }
            ],
            "projects": [
                {
                    "name": os.getenv('CV_PROJ1_NAME', 'Enterprise AI Assistant Ecosystem'),
                    "tech": os.getenv('CV_PROJ1_TECH', 'LangGraph + CrewAI + Multiple LLMs'),
                    "description": os.getenv('CV_PROJ1_DESC', 'Sistema completo de asistentes IA empresariales')
                },
                {
                    "name": os.getenv('CV_PROJ2_NAME', 'AI-Powered Hydroelectric Platform'),
                    "tech": os.getenv('CV_PROJ2_TECH', 'Python + TensorFlow + BigQuery'),
                    "description": os.getenv('CV_PROJ2_DESC', 'Plataforma ML para predicci√≥n energ√≠a')
                }
            ]
        }
    
    def setup_ai(self):
        """Configurar IA y crear archivos YAML necesarios"""
        try:
            print("üß† CONFIGURANDO IA...")
            
            if not DEEPSEEK_API_KEY:
                print("‚ùå DEEPSEEK_API_KEY falta")
                return
            
            # Configurar variables de entorno
            os.environ["OPENAI_API_KEY"] = DEEPSEEK_API_KEY
            os.environ["OPENAI_API_BASE"] = DEEPSEEK_BASE_URL
            
            # Crear archivos YAML (forma oficial)
            self.create_yaml_configs()
            
            self.use_ai = True
            print("üéØ IA CONFIGURADA")
            
        except Exception as e:
            print(f"üí• Error setup_ai: {e}")
            self.use_ai = False
    
    def create_yaml_configs(self):
        """Crea archivos YAML con la estructura oficial CrewAI 2025"""
        try:
            print("üìÅ Creando configuraciones YAML...")
            
            # Crear directorio config
            os.makedirs('config', exist_ok=True)
            
            # agents.yaml con estructura oficial
            agents_yaml = f"""# Agents configuration for Digital Twin

cv_expert:
  role: "AI Expert & Digital Consultant"
  goal: "Provide helpful, professional information about AI technology and {self.cv_data['name']}'s expertise"
  backstory: |
    You are {self.cv_data['name']}, a {self.cv_data['title']} based in {self.cv_data['location']}.
    
    Your expertise includes: {', '.join(self.cv_data['skills'])}.
    
    Current role: {self.cv_data['experience'][0]['role']} at {self.cv_data['experience'][0]['company']}.
    
    You have extensive experience in:
    - {self.cv_data['experience'][0]['highlights']}
    - {self.cv_data['experience'][1]['highlights']}
    
    Notable projects:
    - {self.cv_data['projects'][0]['name']}: {self.cv_data['projects'][0]['description']}
    - {self.cv_data['projects'][1]['name']}: {self.cv_data['projects'][1]['description']}
    
    You are knowledgeable, professional, and helpful. Always provide accurate information
    about AI, technology, and your professional background. Be conversational but informative.
"""
            
            # tasks.yaml con estructura oficial
            tasks_yaml = """# Tasks configuration for Digital Twin

respond_to_query:
  description: |
    Respond to the user's query: {query}
    
    Provide a helpful, professional response based on your expertise in AI and technology.
    Be conversational but informative. If asked about your background, use the information
    from your backstory.
    
    Guidelines:
    - Be professional but friendly
    - Provide specific technical details when relevant
    - Share project experience when applicable
    - Offer to discuss further collaboration if appropriate
  expected_output: "A helpful, professional response to the user's query in Spanish (unless they write in English)"
  agent: cv_expert
"""
            
            # Escribir archivos
            with open('config/agents.yaml', 'w', encoding='utf-8') as f:
                f.write(agents_yaml)
            
            with open('config/tasks.yaml', 'w', encoding='utf-8') as f:
                f.write(tasks_yaml)
            
            print("‚úÖ Archivos YAML creados")
            
        except Exception as e:
            print(f"‚ùå Error creando YAML: {e}")
            raise
    
    async def process_query(self, message: str) -> str:
        """Procesa consulta usando CrewAI con YAML (forma oficial)"""
        print(f"üîç Procesando: '{message}' - IA habilitada: {self.use_ai}")
        
        if self.use_ai:
            try:
                return await self.ai_response_yaml(message)
            except Exception as e:
                print(f"üí• ERROR CON IA: {e}")
                import traceback
                traceback.print_exc()
                return self.fallback_response(message)
        
        return self.simple_response(message)
    
    async def ai_response_yaml(self, message: str) -> str:
        """Respuesta usando CrewAI con YAML - Forma oficial 2025"""
        try:
            # Importar CrewAI con estructura oficial
            from crewai import Agent, Task, Crew, Process
            from crewai.project import CrewBase, agent, task, crew
            
            # Crear clase Crew usando decoradores oficiales
            @CrewBase
            class DigitalTwinCrew:
                """Digital Twin crew using YAML configs"""
                
                # Rutas a archivos YAML (forma oficial)
                agents_config = 'config/agents.yaml'
                tasks_config = 'config/tasks.yaml'
                
                @agent
                def cv_expert(self) -> Agent:
                    """CV Expert agent from YAML config"""
                    return Agent(
                        config=self.agents_config['cv_expert'],
                        verbose=True,
                        allow_delegation=False
                    )
                
                @task
                def respond_to_query(self) -> Task:
                    """Response task from YAML config"""
                    return Task(
                        config=self.tasks_config['respond_to_query']
                    )
                
                @crew
                def crew(self) -> Crew:
                    """Digital Twin crew"""
                    return Crew(
                        agents=[self.cv_expert()],
                        tasks=[self.respond_to_query()],
                        process=Process.sequential,
                        verbose=True
                    )
            
            # Crear y ejecutar crew
            digital_twin_crew = DigitalTwinCrew()
            crew_instance = digital_twin_crew.crew()
            
            # Ejecutar con inputs (interpolaci√≥n de variables)
            result = crew_instance.kickoff(inputs={"query": message})
            
            # Extraer resultado
            if hasattr(result, 'raw'):
                return str(result.raw)
            else:
                return str(result)
            
        except ImportError as e:
            print(f"‚ùå CrewAI no disponible: {e}")
            raise Exception("CrewAI no est√° instalado correctamente")
        except Exception as e:
            print(f"‚ùå Error en AI response YAML: {e}")
            raise
    
    def fallback_response(self, message: str) -> str:
        """Respuesta fallback inteligente"""
        msg_lower = message.lower()
        
        # Respuestas espec√≠ficas sobre IA
        if any(word in msg_lower for word in ['ai', 'inteligencia artificial', 'crewai', 'langgraph', 'yaml']):
            return f"""üß† **Mi experiencia en IA y CrewAI:**

Como {self.cv_data['title']}, trabajo con las √∫ltimas tecnolog√≠as:

**üõ†Ô∏è CrewAI & Multi-Agent Systems:**
‚Ä¢ **Estructura YAML**: Configuraci√≥n declarativa (forma recomendada 2025)
‚Ä¢ **CrewBase decorators**: @agent, @task, @crew
‚Ä¢ **Process orchestration**: Sequential y Hierarchical
‚Ä¢ **Tools integration**: Custom tools y APIs externas

**üöÄ Stack t√©cnico completo:**
‚Ä¢ **Frameworks IA:** LangGraph, CrewAI, LangChain, AutoGen
‚Ä¢ **LLMs:** OpenAI, Claude, DeepSeek, Ollama local
‚Ä¢ **MLOps:** TensorFlow, PyTorch, Scikit-learn
‚Ä¢ **Cloud:** AWS, Azure, Google Cloud

**üíº Proyecto destacado:**
*{self.cv_data['projects'][0]['name']}*
üîß {self.cv_data['projects'][0]['tech']}
üìã {self.cv_data['projects'][0]['description']}

**üìà Resultados cuantificados:**
‚Ä¢ Sistemas multi-agente para 50k+ usuarios
‚Ä¢ Reducci√≥n de costos operativos del 40%
‚Ä¢ Mejora en tiempo de respuesta del 60%

¬øTe interesa implementar CrewAI en tu proyecto?"""
        
        return self.simple_response(message)
    
    def simple_response(self, message: str) -> str:
        """Respuestas b√°sicas sin IA"""
        msg_lower = message.lower()
        
        if any(word in msg_lower for word in ['hola', 'hello', 'hi', 'hey']):
            return f"""üëã **¬°Hola! Soy {self.cv_data['name']}**

*{self.cv_data['bio']}*

üéØ **Especializaci√≥n:**
‚Ä¢ Sistemas IA multi-agente (CrewAI, LangGraph)
‚Ä¢ Arquitectura empresarial y MLOps
‚Ä¢ Integraci√≥n de LLMs y automatizaci√≥n

üõ†Ô∏è **Tech Stack:**
{', '.join(self.cv_data['skills'][:8])}

üìç {self.cv_data['location']}
‚ö° {self.cv_data['availability']}

**¬øEn qu√© puedo ayudarte con IA y tecnolog√≠a?**"""

        elif any(word in msg_lower for word in ['experiencia', 'skills', 'tecnolog√≠a']):
            return f"""üíº **Mi experiencia profesional:**

**üöÄ Rol actual:**
{self.cv_data['experience'][0]['role']} en *{self.cv_data['experience'][0]['company']}*

üèÜ **Logros destacados:**
{self.cv_data['experience'][0]['highlights']}

**üìö Experiencia previa:**
{self.cv_data['experience'][1]['role']} en *{self.cv_data['experience'][1]['company']}*

**üõ†Ô∏è Stack completo:**
{', '.join(self.cv_data['skills'])}

**üéØ Especializaci√≥n 2025:**
‚Ä¢ CrewAI con configuraci√≥n YAML
‚Ä¢ Multi-agent orchestration
‚Ä¢ Enterprise AI architecture

¬øHay alguna tecnolog√≠a espec√≠fica que te interese?"""

        elif any(word in msg_lower for word in ['proyecto', 'portfolio']):
            projects_text = "\n\n".join([
                f"**{i+1}. {proj['name']}**\nüõ†Ô∏è *Tech:* {proj['tech']}\nüìã {proj['description']}"
                for i, proj in enumerate(self.cv_data['projects'])
            ])
            
            return f"""üöÄ **Proyectos destacados:**

{projects_text}

**üìä M√©tricas de impacto:**
‚Ä¢ Sistemas que procesan 1M+ transacciones/d√≠a
‚Ä¢ Arquitecturas multi-agente para 50k+ usuarios
‚Ä¢ Optimizaci√≥n de costos del 40%
‚Ä¢ Mejora en tiempo de respuesta del 60%

**üîß Tecnolog√≠as aplicadas:**
‚Ä¢ CrewAI con YAML configs
‚Ä¢ LangGraph para workflows complejos
‚Ä¢ Integraci√≥n multi-LLM
‚Ä¢ MLOps y CI/CD

¬øTe interesa conocer detalles t√©cnicos?"""

        elif any(word in msg_lower for word in ['disponible', 'contratar', 'colaborar']):
            return f"""