# ðŸ¤– Digital Twin - Telegram Bot Corregido y Actualizado
# Sintaxis CrewAI 2025 verificada y correcta

import os
import asyncio
from typing import Dict, Any
import logging

# Configurar logging
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

print("ðŸ” INICIANDO IMPORTS...")

try:
    from telegram import Update
    from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
    print("âœ… Telegram importado")
except Exception as e:
    print(f"âŒ Error Telegram: {e}")
    exit(1)

print("âœ… TODOS LOS IMPORTS OK")

# Configuration
TELEGRAM_TOKEN = os.getenv('TELEGRAM_TOKEN', '')
DEEPSEEK_API_KEY = os.getenv('DEEPSEEK_API_KEY', '')
DEEPSEEK_BASE_URL = os.getenv('DEEPSEEK_BASE_URL', 'https://api.deepseek.com/v1')

print(f"ðŸ”‘ TELEGRAM_TOKEN: {'âœ… OK' if TELEGRAM_TOKEN else 'âŒ FALTA'}")
print(f"ðŸ”‘ DEEPSEEK_API_KEY: {'âœ… OK' if DEEPSEEK_API_KEY else 'âŒ FALTA'}")


class SimpleDigitalTwin:
    """ðŸ¤– Digital Twin con CrewAI sintaxis 2025"""
    
    def __init__(self):
        print("ðŸ¤– Inicializando Digital Twin...")
        self.cv_data = self.load_cv_data()
        self.use_ai = False
        
        # Solo intentar AI si hay API key
        if DEEPSEEK_API_KEY:
            try:
                self.setup_ai()
            except Exception as e:
                print(f"âš ï¸ AI fallÃ³, modo simple: {e}")
        
        print("âœ… Digital Twin listo")
    
    def load_cv_data(self) -> Dict[str, Any]:
        """Carga CV desde env vars"""
        return {
            "name": os.getenv('CV_NAME', 'Norbert RodrÃ­guez Sagarra'),
            "title": os.getenv('CV_TITLE', 'Senior AI Engineer & Project Manager'),
            "location": os.getenv('CV_LOCATION', 'Barcelona, EspaÃ±a'),
            "bio": os.getenv('CV_BIO', 'Experto en IA, datos y desarrollo de soluciones innovadoras'),
            "skills": os.getenv('CV_SKILLS', 'Python,AI,LangGraph,CrewAI,FastAPI,AWS').split(','),
            "availability": os.getenv('CV_AVAILABILITY', 'Disponible para proyectos de IA y consultorÃ­a'),
            "experience": [
                {
                    "company": os.getenv('CV_EXP1_COMPANY', 'VEOLIA-AGBAR-SYNECTIC'),
                    "role": os.getenv('CV_EXP1_ROLE', 'Senior AI Engineer'),
                    "years": os.getenv('CV_EXP1_YEARS', '2021-2024'),
                    "highlights": os.getenv('CV_EXP1_HIGHLIGHTS', 'Sistemas IA empresariales para 50k+ usuarios')
                },
                {
                    "company": os.getenv('CV_EXP2_COMPANY', 'IBM Collaborative Projects'),
                    "role": os.getenv('CV_EXP2_ROLE', 'AI Solutions Architect'),
                    "years": os.getenv('CV_EXP2_YEARS', '2017-2022'),
                    "highlights": os.getenv('CV_EXP2_HIGHLIGHTS', 'Liderazgo de proyectos IA con Watson')
                }
            ],
            "projects": [
                {
                    "name": os.getenv('CV_PROJ1_NAME', 'Enterprise AI Assistant Ecosystem'),
                    "tech": os.getenv('CV_PROJ1_TECH', 'LangGraph + CrewAI + Multiple LLMs'),
                    "description": os.getenv('CV_PROJ1_DESC', 'Sistema completo de asistentes IA empresariales')
                },
                {
                    "name": os.getenv('CV_PROJ2_NAME', 'AI-Powered Hydroelectric Platform'),
                    "tech": os.getenv('CV_PROJ2_TECH', 'Python + TensorFlow + BigQuery'),
                    "description": os.getenv('CV_PROJ2_DESC', 'Plataforma ML para predicciÃ³n energÃ­a')
                }
            ]
        }
    
    def setup_ai(self):
        """Configurar IA con CrewAI - Sintaxis 2025 corregida"""
        try:
            print("ðŸ§  CONFIGURANDO IA...")
            
            if not DEEPSEEK_API_KEY:
                print("âŒ DEEPSEEK_API_KEY falta")
                return
            
            # Configurar variables de entorno para OpenAI compatible
            os.environ["OPENAI_API_KEY"] = DEEPSEEK_API_KEY
            os.environ["OPENAI_API_BASE"] = DEEPSEEK_BASE_URL
            
            self.use_ai = True
            print("ðŸŽ¯ IA CONFIGURADA")
            
        except Exception as e:
            print(f"ðŸ’¥ Error setup_ai: {e}")
            self.use_ai = False
    
    async def process_query(self, message: str) -> str:
        """Procesa consulta usando CrewAI"""
        print(f"ðŸ” Procesando: '{message}' - IA habilitada: {self.use_ai}")
        
        if self.use_ai:
            try:
                return await self.ai_response(message)
            except Exception as e:
                print(f"ðŸ’¥ ERROR CON IA: {e}")
                import traceback
                traceback.print_exc()
                return self.fallback_response(message)
        
        return self.simple_response(message)
    
    async def ai_response(self, message: str) -> str:
        """Respuesta usando CrewAI - Sintaxis 2025 verificada"""
        try:
            # Importar CrewAI con sintaxis correcta
            from crewai import Agent, Task, Crew, Process
            
            # Configurar LLM usando el patrÃ³n actualizado
            try:
                from langchain_openai import ChatOpenAI
                llm = ChatOpenAI(
                    model="deepseek-chat",
                    base_url=DEEPSEEK_BASE_URL,
                    api_key=DEEPSEEK_API_KEY,
                    temperature=0.7
                )
            except ImportError:
                # Fallback si no estÃ¡ disponible langchain_openai
                print("âš ï¸ langchain_openai no disponible, usando configuraciÃ³n bÃ¡sica")
                llm = None
            
            # Crear agente con sintaxis 2025
            agent = Agent(
                role="AI Expert & Tech Consultant",
                goal="Provide helpful, professional information about AI and technology",
                backstory=f"""You are {self.cv_data['name']}, a {self.cv_data['title']} 
                based in {self.cv_data['location']}.
                
                Your expertise includes: {', '.join(self.cv_data['skills'])}
                
                Current role: {self.cv_data['experience'][0]['role']} at {self.cv_data['experience'][0]['company']}
                
                You are knowledgeable, helpful, and professional. Always provide accurate information
                about AI, technology, and your professional background.""",
                verbose=True,
                allow_delegation=False,
                llm=llm  # Puede ser None y CrewAI usarÃ¡ el default
            )
            
            # Crear tarea con sintaxis 2025
            task = Task(
                description=f"""Respond to this user query: "{message}"
                
                Provide a helpful, professional response based on your expertise in AI and technology.
                Be conversational but informative. If asked about your background, use the information
                from your backstory.""",
                expected_output="A helpful, professional response to the user's query",
                agent=agent
            )
            
            # Crear y ejecutar crew con sintaxis 2025
            crew = Crew(
                agents=[agent],
                tasks=[task],
                process=Process.sequential,  # ExplÃ­citamente especificar proceso
                verbose=True
            )
            
            # Ejecutar crew
            result = crew.kickoff()
            
            # Extraer resultado segÃºn la versiÃ³n de CrewAI
            if hasattr(result, 'raw'):
                return str(result.raw)
            else:
                return str(result)
            
        except ImportError as e:
            print(f"âŒ CrewAI no disponible: {e}")
            raise Exception("CrewAI no estÃ¡ instalado correctamente")
        except Exception as e:
            print(f"âŒ Error en AI response: {e}")
            raise
    
    def fallback_response(self, message: str) -> str:
        """Respuesta fallback inteligente usando datos del CV"""
        msg_lower = message.lower()
        
        # Respuestas especÃ­ficas sobre IA
        if any(word in msg_lower for word in ['ai', 'inteligencia artificial', 'machine learning', 'crewai', 'langgraph']):
            return f"""ðŸ§  **Mi experiencia en IA:**

Como {self.cv_data['title']}, trabajo con tecnologÃ­as de vanguardia:

**ðŸ› ï¸ Stack tecnolÃ³gico:**
â€¢ **Frameworks IA:** LangGraph, CrewAI, LangChain
â€¢ **APIs LLM:** OpenAI, Claude, DeepSeek
â€¢ **ML/DL:** TensorFlow, PyTorch, Scikit-learn
â€¢ **Cloud:** AWS, Azure, Google Cloud

**ðŸš€ Proyecto destacado:**
*{self.cv_data['projects'][0]['name']}*
ðŸ”§ Tech Stack: {self.cv_data['projects'][0]['tech']}
ðŸ“‹ {self.cv_data['projects'][0]['description']}

**ðŸ’¼ Experiencia actual:**
{self.cv_data['experience'][0]['role']} en {self.cv_data['experience'][0]['company']}
ðŸ† {self.cv_data['experience'][0]['highlights']}

Â¿Hay algo especÃ­fico sobre IA que te interese conocer?"""
        
        # Respuesta sobre DeepSeek especÃ­ficamente
        if 'deepseek' in msg_lower:
            return f"""ðŸ¤– **Experiencia con DeepSeek:**

Como {self.cv_data['title']}, he trabajado con varios LLMs incluyendo DeepSeek:

**ðŸ”§ IntegraciÃ³n tÃ©cnica:**
â€¢ API integration con CrewAI
â€¢ OptimizaciÃ³n de prompts
â€¢ ConfiguraciÃ³n multi-modelo
â€¢ Cost optimization strategies

**ðŸ’¡ Ventajas de DeepSeek:**
â€¢ Excelente relaciÃ³n calidad/precio
â€¢ Soporte para APIs OpenAI-compatible
â€¢ Rendimiento competitivo en tareas de cÃ³digo

Â¿Te interesa implementar DeepSeek en tu proyecto?"""
        
        return self.simple_response(message)
    
    def simple_response(self, message: str) -> str:
        """Respuestas bÃ¡sicas sin IA - mejoradas"""
        msg_lower = message.lower()
        
        if any(word in msg_lower for word in ['hola', 'hello', 'hi', 'hey']):
            return f"""ðŸ‘‹ **Â¡Hola! Soy {self.cv_data['name']}**

*{self.cv_data['bio']}*

ðŸŽ¯ **EspecializaciÃ³n:**
â€¢ Sistemas IA empresariales y multi-agente
â€¢ Arquitectura de datos y MLOps
â€¢ IntegraciÃ³n de LLMs y automatizaciÃ³n

ðŸ› ï¸ **Tech Stack actual:**
{', '.join(self.cv_data['skills'][:8])}

ðŸ“ {self.cv_data['location']}
âš¡ {self.cv_data['availability']}

**Â¿En quÃ© puedo ayudarte hoy?**"""

        elif any(word in msg_lower for word in ['experiencia', 'skills', 'tecnologÃ­a', 'trabajo']):
            return f"""ðŸ’¼ **Mi trayectoria profesional:**

**ðŸš€ Rol actual:**
{self.cv_data['experience'][0]['role']} en *{self.cv_data['experience'][0]['company']}* ({self.cv_data['experience'][0]['years']})

ðŸ† **Logros destacados:**
{self.cv_data['experience'][0]['highlights']}

**ðŸ“š Experiencia previa:**
{self.cv_data['experience'][1]['role']} en *{self.cv_data['experience'][1]['company']}*
ðŸŽ¯ {self.cv_data['experience'][1]['highlights']}

**ðŸ› ï¸ Stack tecnolÃ³gico:**
{', '.join(self.cv_data['skills'])}

Â¿Hay alguna tecnologÃ­a especÃ­fica que te interese?"""

        elif any(word in msg_lower for word in ['proyecto', 'portfolio', 'casos']):
            projects_text = "\n\n".join([
                f"**{i+1}. {proj['name']}**\nðŸ› ï¸ *Tech:* {proj['tech']}\nðŸ“‹ {proj['description']}"
                for i, proj in enumerate(self.cv_data['projects'])
            ])
            
            return f"""ðŸš€ **Proyectos destacados:**

{projects_text}

**ðŸ“Š Impacto cuantificado:**
â€¢ Sistemas que procesan 1M+ transacciones/dÃ­a
â€¢ Plataformas que sirven a 50k+ usuarios activos
â€¢ ReducciÃ³n de costos operativos del 40%
â€¢ Mejora en tiempo de respuesta del 60%

Â¿Te interesa conocer detalles tÃ©cnicos de algÃºn proyecto?"""

        elif any(word in msg_lower for word in ['disponible', 'contratar', 'contacto', 'colaborar']):
            return f"""ðŸ“… **Disponibilidad y colaboraciÃ³n:**

âš¡ **Estado actual:** {self.cv_data['availability']}

**ðŸŽ¯ Servicios que ofrezco:**
â€¢ ðŸ¤– Desarrollo de sistemas IA multi-agente
â€¢ ðŸ”— IntegraciÃ³n de LLMs (GPT, Claude, DeepSeek)
â€¢ ðŸ—ï¸ Arquitectura de datos y MLOps
â€¢ ðŸ’¡ ConsultorÃ­a en transformaciÃ³n digital IA

**ðŸ“‹ Para iniciar colaboraciÃ³n, compÃ¡rteme:**
â€¢ ðŸ“§ Tu email de contacto
â€¢ ðŸ¢ Empresa/proyecto
â€¢ ðŸŽ¯ DescripciÃ³n del desafÃ­o tÃ©cnico
â€¢ âš¡ TecnologÃ­as involucradas
â€¢ ðŸ“… Timeline esperado

**â±ï¸ GarantÃ­a: Respuesta en menos de 24 horas**

Â¿En quÃ© proyecto estÃ¡s trabajando?"""

        elif any(word in msg_lower for word in ['precio', 'coste', 'tarifa', 'presupuesto']):
            return f"""ðŸ’° **Estructura de colaboraciÃ³n:**

Como {self.cv_data['title']}, ofrezco diferentes modalidades:

**ðŸŽ¯ ConsultorÃ­a estratÃ©gica:**
â€¢ AuditorÃ­a de arquitectura IA
â€¢ Roadmap tecnolÃ³gico
â€¢ Due diligence tÃ©cnico

**ðŸ› ï¸ Desarrollo tÃ©cnico:**
â€¢ ImplementaciÃ³n de sistemas IA
â€¢ IntegraciÃ³n de LLMs
â€¢ MLOps y automatizaciÃ³n

**ðŸ“‹ Para presupuesto personalizado:**
â€¢ Describe el scope del proyecto
â€¢ Timeline y urgencia
â€¢ Recursos tÃ©cnicos disponibles
â€¢ Complejidad estimada

Cada proyecto es Ãºnico - prefiero discutir detalles antes de dar cifras.

Â¿CuÃ¡l es tu proyecto especÃ­fico?"""

        else:
            return f"""ðŸ¤– **Soy {self.cv_data['name']}**
*{self.cv_data['title']}*

**ðŸ§  Experto en:**
â€¢ Inteligencia Artificial y Machine Learning
â€¢ Sistemas multi-agente (CrewAI, LangGraph)
â€¢ Arquitectura de datos enterprise
â€¢ IntegraciÃ³n de LLMs y automatizaciÃ³n

**ðŸ’¬ Puedes preguntarme sobre:**
â€¢ ðŸ”§ Experiencia tÃ©cnica y proyectos
â€¢ ðŸš€ TecnologÃ­as de IA y mejores prÃ¡cticas
â€¢ ðŸ“… Disponibilidad para colaboraciones
â€¢ ðŸ’¡ Soluciones especÃ­ficas a tus desafÃ­os

**Â¿QuÃ© aspecto especÃ­fico te interesa explorar?**"""


class TelegramBot:
    """ðŸ¤– Bot de Telegram optimizado"""
    
    def __init__(self):
        print("ðŸ¤– Inicializando bot...")
        
        if not TELEGRAM_TOKEN:
            print("âŒ TELEGRAM_TOKEN requerido")
            exit(1)
            
        self.digital_twin = SimpleDigitalTwin()
        self.app = Application.builder().token(TELEGRAM_TOKEN).build()
        self.setup_handlers()
        print("âœ… Bot inicializado")
    
    def setup_handlers(self):
        """Configurar handlers del bot"""
        self.app.add_handler(CommandHandler("start", self.start_command))
        self.app.add_handler(CommandHandler("help", self.help_command))
        self.app.add_handler(CommandHandler("about", self.about_command))
        self.app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, self.handle_message))
    
    async def start_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Comando start mejorado"""
        cv = self.digital_twin.cv_data
        
        welcome = f"""ðŸš€ **Â¡Bienvenido al Digital Twin de {cv['name']}!**

*{cv['bio']}*

ðŸ“ **UbicaciÃ³n:** {cv['location']}
ðŸ’¼ **Rol actual:** {cv['title']}
âš¡ **Estado:** {cv['availability']}

**ðŸŽ¯ Soy especialista en:**
â€¢ Sistemas IA empresariales y multi-agente
â€¢ LangGraph, CrewAI, integraciÃ³n de LLMs
â€¢ Arquitectura de datos y MLOps

**ðŸ’¬ Comandos disponibles:**
â€¢ `/help` - Ver todas las opciones
â€¢ `/about` - Conocer mi experiencia detallada

**Â¡PregÃºntame cualquier cosa sobre IA y tecnologÃ­a!** ðŸ¤–"""
        
        await update.message.reply_text(welcome, parse_mode='Markdown')
    
    async def help_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Comando help mejorado"""
        help_text = """ðŸ“‹ **Â¿CÃ³mo puedo ayudarte?**

**ðŸ” Temas de consulta:**
â€¢ ðŸ’» **Experiencia tÃ©cnica** - Skills, proyectos, tecnologÃ­as
â€¢ ðŸ§  **Inteligencia Artificial** - CrewAI, LangGraph, LLMs
â€¢ ðŸš€ **Casos de uso** - Proyectos reales, implementaciones
â€¢ ðŸ“… **ColaboraciÃ³n** - Disponibilidad, servicios, presupuestos
â€¢ ðŸŽ¯ **Soluciones especÃ­ficas** - Tu desafÃ­o tÃ©cnico particular

**ðŸ’¡ Ejemplos de preguntas:**
â€¢ "Â¿QuÃ© experiencia tienes con CrewAI?"
â€¢ "Â¿CÃ³mo integrarÃ­as DeepSeek en un sistema empresarial?"
â€¢ "CuÃ©ntame sobre tus proyectos de IA"
â€¢ "Â¿EstÃ¡s disponible para consultorÃ­a?"

**ðŸ¤– Â¡Solo escribe tu pregunta en lenguaje natural!**"""
        
        await update.message.reply_text(help_text, parse_mode='Markdown')
    
    async def about_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Comando about con informaciÃ³n detallada"""
        cv = self.digital_twin.cv_data
        
        about_text = f"""ðŸ‘¨â€ðŸ’» **{cv['name']}**
*{cv['title']}*

**ðŸ¢ Experiencia profesional:**

**ðŸš€ Actual:** {cv['experience'][0]['role']}
ðŸ“ {cv['experience'][0]['company']} ({cv['experience'][0]['years']})
ðŸ† {cv['experience'][0]['highlights']}

**ðŸ“š Anterior:** {cv['experience'][1]['role']}
ðŸ“ {cv['experience'][1]['company']} ({cv['experience'][1]['years']})
ðŸŽ¯ {cv['experience'][1]['highlights']}

**ðŸ› ï¸ Stack tecnolÃ³gico:**
{', '.join(cv['skills'])}

**ðŸ’¡ Enfoque:**
Especializado en democratizar la IA empresarial mediante sistemas multi-agente inteligentes y arquitecturas escalables.

Â¿Quieres conocer algÃºn aspecto especÃ­fico?"""
        
        await update.message.reply_text(about_text, parse_mode='Markdown')
    
    async def handle_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Maneja mensajes de texto con mejor UX"""
        try:
            # Mostrar typing indicator
            await context.bot.send_chat_action(
                chat_id=update.effective_chat.id, 
                action="typing"
            )
            
            # Procesar mensaje
            response = await self.digital_twin.process_query(update.message.text)
            
            # Dividir respuesta si es muy larga
            if len(response) > 4096:
                # Telegram tiene lÃ­mite de 4096 caracteres
                parts = [response[i:i+4000] for i in range(0, len(response), 4000)]
                for part in parts:
                    await update.message.reply_text(part, parse_mode='Markdown')
            else:
                await update.message.reply_text(response, parse_mode='Markdown')
            
            # Log para debug
            user = update.effective_user
            print(f"ðŸ‘¤ {user.first_name} ({user.id}): {update.message.text[:100]}...")
            print(f"ðŸ¤– Respuesta enviada ({len(response)} chars)")
            
        except Exception as e:
            logger.error(f"Error handling message: {e}")
            
            # Mensaje de error amigable
            error_msg = """ðŸ¤– Disculpa, encontrÃ© un problema tÃ©cnico.

**Â¿Puedes intentar:**
â€¢ Reformular tu pregunta
â€¢ Usar `/help` para ver opciones
â€¢ Contactar directamente si es urgente

*Estoy trabajando para solucionarlo.* ðŸ”§"""
            
            await update.message.reply_text(error_msg, parse_mode='Markdown')
    
    async def cleanup_webhook(self):
        """Limpia webhooks previos"""
        try:
            print("ðŸ§¹ Limpiando conexiones previas...")
            await self.app.bot.delete_webhook(drop_pending_updates=True)
            await asyncio.sleep(2)
            print("âœ… Conexiones limpiadas")
        except Exception as e:
            print(f"âš ï¸ Error limpiando conexiones: {e}")
    
    def start_bot(self):
        """Inicia el bot con manejo robusto de errores"""
        try:
            print("ðŸš€ INICIANDO TELEGRAM BOT...")
            
            # Limpiar conexiones previas
            asyncio.run(self.cleanup_webhook())
            
            # Iniciar polling con configuraciÃ³n optimizada
            print("ðŸ”„ Iniciando polling...")
            self.app.run_polling(
                drop_pending_updates=True,
                timeout=30,
                poll_interval=1.0,
                bootstrap_retries=5
            )
            
        except KeyboardInterrupt:
            print("ðŸ‘‹ Bot detenido por usuario")
        except Exception as e:
            logger.error(f"Error crÃ­tico en bot: {e}")
            import traceback
            traceback.print_exc()
            raise


if __name__ == "__main__":
    print("ðŸš€ INICIANDO DIGITAL TWIN BOT...")
    
    try:
        bot = TelegramBot()
        bot.start_bot()
    except Exception as e:
        print(f"âŒ Error fatal: {e}")
        print("\nðŸ’¡ Verifica:")
        print("â€¢ TELEGRAM_TOKEN configurado")
        print("â€¢ Dependencias instaladas: pip install python-telegram-bot crewai")
        print("â€¢ Python >= 3.10")
        exit(1)