# ğŸ¤– Digital Twin - Telegram Bot con YAML (Forma oficial CrewAI 2025)
# Usando la estructura recomendada: CrewBase + YAML configs

import os
import asyncio
from typing import Dict, Any
import logging

# Configurar logging
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

print("ğŸ” INICIANDO IMPORTS...")

try:
    from telegram import Update
    from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
    print("âœ… Telegram importado")
except Exception as e:
    print(f"âŒ Error Telegram: {e}")
    exit(1)

print("âœ… TODOS LOS IMPORTS OK")

# Configuration
TELEGRAM_TOKEN = os.getenv('TELEGRAM_TOKEN', '')
DEEPSEEK_API_KEY = os.getenv('DEEPSEEK_API_KEY', '')
DEEPSEEK_BASE_URL = os.getenv('DEEPSEEK_BASE_URL', 'https://api.deepseek.com/v1')

print(f"ğŸ”‘ TELEGRAM_TOKEN: {'âœ… OK' if TELEGRAM_TOKEN else 'âŒ FALTA'}")
print(f"ğŸ”‘ DEEPSEEK_API_KEY: {'âœ… OK' if DEEPSEEK_API_KEY else 'âŒ FALTA'}")


class SimpleDigitalTwin:
    """ğŸ¤– Digital Twin usando YAML configs (forma oficial CrewAI 2025)"""
    
    def __init__(self):
        print("ğŸ¤– Inicializando Digital Twin...")
        self.cv_data = self.load_cv_data()
        self.use_ai = False
        
        # Solo intentar AI si hay API key
        if DEEPSEEK_API_KEY:
            try:
                self.setup_ai()
            except Exception as e:
                print(f"âš ï¸ AI fallÃ³, modo simple: {e}")
        
        print("âœ… Digital Twin listo")
    
    def load_cv_data(self) -> Dict[str, Any]:
        """Carga CV desde env vars"""
        return {
            "name": os.getenv('CV_NAME', 'Norbert RodrÃ­guez Sagarra'),
            "title": os.getenv('CV_TITLE', 'Senior AI Engineer & Project Manager'),
            "location": os.getenv('CV_LOCATION', 'Barcelona, EspaÃ±a'),
            "bio": os.getenv('CV_BIO', 'Experto en IA, datos y desarrollo de soluciones innovadoras'),
            "skills": os.getenv('CV_SKILLS', 'Python,AI,LangGraph,CrewAI,FastAPI,AWS').split(','),
            "availability": os.getenv('CV_AVAILABILITY', 'Disponible para proyectos de IA y consultorÃ­a'),
            "experience": [
                {
                    "company": os.getenv('CV_EXP1_COMPANY', 'VEOLIA-AGBAR-SYNECTIC'),
                    "role": os.getenv('CV_EXP1_ROLE', 'Senior AI Engineer'),
                    "years": os.getenv('CV_EXP1_YEARS', '2021-2024'),
                    "highlights": os.getenv('CV_EXP1_HIGHLIGHTS', 'Sistemas IA empresariales para 50k+ usuarios')
                },
                {
                    "company": os.getenv('CV_EXP2_COMPANY', 'IBM Collaborative Projects'),
                    "role": os.getenv('CV_EXP2_ROLE', 'AI Solutions Architect'),
                    "years": os.getenv('CV_EXP2_YEARS', '2017-2022'),
                    "highlights": os.getenv('CV_EXP2_HIGHLIGHTS', 'Liderazgo de proyectos IA con Watson')
                }
            ],
            "projects": [
                {
                    "name": os.getenv('CV_PROJ1_NAME', 'Enterprise AI Assistant Ecosystem'),
                    "tech": os.getenv('CV_PROJ1_TECH', 'LangGraph + CrewAI + Multiple LLMs'),
                    "description": os.getenv('CV_PROJ1_DESC', 'Sistema completo de asistentes IA empresariales')
                },
                {
                    "name": os.getenv('CV_PROJ2_NAME', 'AI-Powered Hydroelectric Platform'),
                    "tech": os.getenv('CV_PROJ2_TECH', 'Python + TensorFlow + BigQuery'),
                    "description": os.getenv('CV_PROJ2_DESC', 'Plataforma ML para predicciÃ³n energÃ­a')
                }
            ]
        }
    
    def setup_ai(self):
        """Configurar IA y crear archivos YAML necesarios"""
        try:
            print("ğŸ§  CONFIGURANDO IA...")
            
            if not DEEPSEEK_API_KEY:
                print("âŒ DEEPSEEK_API_KEY falta")
                return
            
            # Configurar variables de entorno
            os.environ["OPENAI_API_KEY"] = DEEPSEEK_API_KEY
            os.environ["OPENAI_API_BASE"] = DEEPSEEK_BASE_URL
            
            # Crear archivos YAML (forma oficial)
            self.create_yaml_configs()
            
            self.use_ai = True
            print("ğŸ¯ IA CONFIGURADA")
            
        except Exception as e:
            print(f"ğŸ’¥ Error setup_ai: {e}")
            self.use_ai = False
    
    def create_yaml_configs(self):
        """Crea archivos YAML con la estructura oficial CrewAI 2025"""
        try:
            print("ğŸ“ Creando configuraciones YAML...")
            
            # Crear directorio config
            os.makedirs('config', exist_ok=True)
            
            # agents.yaml con estructura oficial
            agents_yaml = f"""# Agents configuration for Digital Twin

cv_expert:
  role: "AI Expert & Digital Consultant"
  goal: "Provide helpful, professional information about AI technology and {self.cv_data['name']}'s expertise"
  backstory: |
    You are {self.cv_data['name']}, a {self.cv_data['title']} based in {self.cv_data['location']}.
    
    Your expertise includes: {', '.join(self.cv_data['skills'])}.
    
    Current role: {self.cv_data['experience'][0]['role']} at {self.cv_data['experience'][0]['company']}.
    
    You have extensive experience in:
    - {self.cv_data['experience'][0]['highlights']}
    - {self.cv_data['experience'][1]['highlights']}
    
    Notable projects:
    - {self.cv_data['projects'][0]['name']}: {self.cv_data['projects'][0]['description']}
    - {self.cv_data['projects'][1]['name']}: {self.cv_data['projects'][1]['description']}
    
    You are knowledgeable, professional, and helpful. Always provide accurate information
    about AI, technology, and your professional background. Be conversational but informative.
"""
            
            # tasks.yaml con estructura oficial
            tasks_yaml = """# Tasks configuration for Digital Twin

respond_to_query:
  description: |
    Respond to the user's query: {query}
    
    Provide a helpful, professional response based on your expertise in AI and technology.
    Be conversational but informative. If asked about your background, use the information
    from your backstory.
    
    Guidelines:
    - Be professional but friendly
    - Provide specific technical details when relevant
    - Share project experience when applicable
    - Offer to discuss further collaboration if appropriate
  expected_output: "A helpful, professional response to the user's query in Spanish (unless they write in English)"
  agent: cv_expert
"""
            
            # Escribir archivos
            with open('config/agents.yaml', 'w', encoding='utf-8') as f:
                f.write(agents_yaml)
            
            with open('config/tasks.yaml', 'w', encoding='utf-8') as f:
                f.write(tasks_yaml)
            
            print("âœ… Archivos YAML creados")
            
        except Exception as e:
            print(f"âŒ Error creando YAML: {e}")
            raise
    
    async def process_query(self, message: str) -> str:
        """Procesa consulta usando CrewAI con YAML (forma oficial)"""
        print(f"ğŸ” Procesando: '{message}' - IA habilitada: {self.use_ai}")
        
        if self.use_ai:
            try:
                return await self.ai_response_yaml(message)
            except Exception as e:
                print(f"ğŸ’¥ ERROR CON IA: {e}")
                import traceback
                traceback.print_exc()
                return self.fallback_response(message)
        
        return self.simple_response(message)
    
    async def ai_response_yaml(self, message: str) -> str:
        """Respuesta usando CrewAI con YAML - Forma oficial 2025"""
        try:
            # Importar CrewAI con estructura oficial
            from crewai import Agent, Task, Crew, Process
            from crewai.project import CrewBase, agent, task, crew
            
            # Crear clase Crew usando decoradores oficiales
            @CrewBase
            class DigitalTwinCrew:
                """Digital Twin crew using YAML configs"""
                
                # Rutas a archivos YAML (forma oficial)
                agents_config = 'config/agents.yaml'
                tasks_config = 'config/tasks.yaml'
                
                @agent
                def cv_expert(self) -> Agent:
                    """CV Expert agent from YAML config"""
                    return Agent(
                        config=self.agents_config['cv_expert'],
                        verbose=True,
                        allow_delegation=False
                    )
                
                @task
                def respond_to_query(self) -> Task:
                    """Response task from YAML config"""
                    return Task(
                        config=self.tasks_config['respond_to_query']
                    )
                
                @crew
                def crew(self) -> Crew:
                    """Digital Twin crew"""
                    return Crew(
                        agents=[self.cv_expert()],
                        tasks=[self.respond_to_query()],
                        process=Process.sequential,
                        verbose=True
                    )
            
            # Crear y ejecutar crew
            digital_twin_crew = DigitalTwinCrew()
            crew_instance = digital_twin_crew.crew()
            
            # Ejecutar con inputs (interpolaciÃ³n de variables)
            result = crew_instance.kickoff(inputs={"query": message})
            
            # Extraer resultado
            if hasattr(result, 'raw'):
                return str(result.raw)
            else:
                return str(result)
            
        except ImportError as e:
            print(f"âŒ CrewAI no disponible: {e}")
            raise Exception("CrewAI no estÃ¡ instalado correctamente")
        except Exception as e:
            print(f"âŒ Error en AI response YAML: {e}")
            raise
    
    def fallback_response(self, message: str) -> str:
        """Respuesta fallback inteligente"""
        msg_lower = message.lower()
        
        # Respuestas especÃ­ficas sobre IA
        if any(word in msg_lower for word in ['ai', 'inteligencia artificial', 'crewai', 'langgraph', 'yaml']):
            return f"""ğŸ§  **Mi experiencia en IA y CrewAI:**

Como {self.cv_data['title']}, trabajo con las Ãºltimas tecnologÃ­as:

**ğŸ› ï¸ CrewAI & Multi-Agent Systems:**
â€¢ **Estructura YAML**: ConfiguraciÃ³n declarativa (forma recomendada 2025)
â€¢ **CrewBase decorators**: @agent, @task, @crew
â€¢ **Process orchestration**: Sequential y Hierarchical
â€¢ **Tools integration**: Custom tools y APIs externas

**ğŸš€ Stack tÃ©cnico completo:**
â€¢ **Frameworks IA:** LangGraph, CrewAI, LangChain, AutoGen
â€¢ **LLMs:** OpenAI, Claude, DeepSeek, Ollama local
â€¢ **MLOps:** TensorFlow, PyTorch, Scikit-learn
â€¢ **Cloud:** AWS, Azure, Google Cloud

**ğŸ’¼ Proyecto destacado:**
*{self.cv_data['projects'][0]['name']}*
ğŸ”§ {self.cv_data['projects'][0]['tech']}
ğŸ“‹ {self.cv_data['projects'][0]['description']}

**ğŸ“ˆ Resultados cuantificados:**
â€¢ Sistemas multi-agente para 50k+ usuarios
â€¢ ReducciÃ³n de costos operativos del 40%
â€¢ Mejora en tiempo de respuesta del 60%

Â¿Te interesa implementar CrewAI en tu proyecto?"""
        
        return self.simple_response(message)
    
    def simple_response(self, message: str) -> str:
        """Respuestas bÃ¡sicas sin IA"""
        msg_lower = message.lower()
        
        if any(word in msg_lower for word in ['hola', 'hello', 'hi', 'hey']):
            return f"""ğŸ‘‹ **Â¡Hola! Soy {self.cv_data['name']}**

*{self.cv_data['bio']}*

ğŸ¯ **EspecializaciÃ³n:**
â€¢ Sistemas IA multi-agente (CrewAI, LangGraph)
â€¢ Arquitectura empresarial y MLOps
â€¢ IntegraciÃ³n de LLMs y automatizaciÃ³n

ğŸ› ï¸ **Tech Stack:**
{', '.join(self.cv_data['skills'][:8])}

ğŸ“ {self.cv_data['location']}
âš¡ {self.cv_data['availability']}

**Â¿En quÃ© puedo ayudarte con IA y tecnologÃ­a?**"""

        elif any(word in msg_lower for word in ['experiencia', 'skills', 'tecnologÃ­a']):
            return f"""ğŸ’¼ **Mi experiencia profesional:**

**ğŸš€ Rol actual:**
{self.cv_data['experience'][0]['role']} en *{self.cv_data['experience'][0]['company']}*

ğŸ† **Logros destacados:**
{self.cv_data['experience'][0]['highlights']}

**ğŸ“š Experiencia previa:**
{self.cv_data['experience'][1]['role']} en *{self.cv_data['experience'][1]['company']}*

**ğŸ› ï¸ Stack completo:**
{', '.join(self.cv_data['skills'])}

**ğŸ¯ EspecializaciÃ³n 2025:**
â€¢ CrewAI con configuraciÃ³n YAML
â€¢ Multi-agent orchestration
â€¢ Enterprise AI architecture

Â¿Hay alguna tecnologÃ­a especÃ­fica que te interese?"""

        elif any(word in msg_lower for word in ['proyecto', 'portfolio']):
            projects_text = "\n\n".join([
                f"**{i+1}. {proj['name']}**\nğŸ› ï¸ *Tech:* {proj['tech']}\nğŸ“‹ {proj['description']}"
                for i, proj in enumerate(self.cv_data['projects'])
            ])
            
            return f"""ğŸš€ **Proyectos destacados:**

{projects_text}

**ğŸ“Š MÃ©tricas de impacto:**
â€¢ Sistemas que procesan 1M+ transacciones/dÃ­a
â€¢ Arquitecturas multi-agente para 50k+ usuarios
â€¢ OptimizaciÃ³n de costos del 40%
â€¢ Mejora en tiempo de respuesta del 60%

**ğŸ”§ TecnologÃ­as aplicadas:**
â€¢ CrewAI con YAML configs
â€¢ LangGraph para workflows complejos
â€¢ IntegraciÃ³n multi-LLM
â€¢ MLOps y CI/CD

Â¿Te interesa conocer detalles tÃ©cnicos?"""

        elif any(word in msg_lower for word in ['disponible', 'contratar', 'colaborar']):
            return f"""