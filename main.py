# ü§ñ Digital Twin - Telegram Bot Corregido y Actualizado
# Sintaxis CrewAI 2025 verificada y correcta

import os
import asyncio
from typing import Dict, Any
import logging

# Configurar logging
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

print("üîç INICIANDO IMPORTS...")

try:
    from telegram import Update
    from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
    print("‚úÖ Telegram importado")
except Exception as e:
    print(f"‚ùå Error Telegram: {e}")
    exit(1)

print("‚úÖ TODOS LOS IMPORTS OK")

# Configuration
TELEGRAM_TOKEN = os.getenv('TELEGRAM_TOKEN', '')
DEEPSEEK_API_KEY = os.getenv('DEEPSEEK_API_KEY', '')
DEEPSEEK_BASE_URL = os.getenv('DEEPSEEK_BASE_URL', 'https://api.deepseek.com/v1')

print(f"üîë TELEGRAM_TOKEN: {'‚úÖ OK' if TELEGRAM_TOKEN else '‚ùå FALTA'}")
print(f"üîë DEEPSEEK_API_KEY: {'‚úÖ OK' if DEEPSEEK_API_KEY else '‚ùå FALTA'}")


class SimpleDigitalTwin:
    """ü§ñ Digital Twin con CrewAI sintaxis 2025"""
    
    def __init__(self):
        print("ü§ñ Inicializando Digital Twin...")
        self.cv_data = self.load_cv_data()
        self.use_ai = False
        
        # Solo intentar AI si hay API key
        if DEEPSEEK_API_KEY:
            try:
                self.setup_ai()
            except Exception as e:
                print(f"‚ö†Ô∏è AI fall√≥, modo simple: {e}")
        
        print("‚úÖ Digital Twin listo")
    
    def load_cv_data(self) -> Dict[str, Any]:
        """Carga CV desde env vars"""
        return {
            "name": os.getenv('CV_NAME', 'Norbert Rodr√≠guez Sagarra'),
            "title": os.getenv('CV_TITLE', 'Senior AI Engineer & Project Manager'),
            "location": os.getenv('CV_LOCATION', 'Barcelona, Espa√±a'),
            "bio": os.getenv('CV_BIO', 'Experto en IA, datos y desarrollo de soluciones innovadoras'),
            "skills": os.getenv('CV_SKILLS', 'Python,AI,LangGraph,CrewAI,FastAPI,AWS').split(','),
            "availability": os.getenv('CV_AVAILABILITY', 'Disponible para proyectos de IA y consultor√≠a'),
            "experience": [
                {
                    "company": os.getenv('CV_EXP1_COMPANY', 'VEOLIA-AGBAR-SYNECTIC'),
                    "role": os.getenv('CV_EXP1_ROLE', 'Senior AI Engineer'),
                    "years": os.getenv('CV_EXP1_YEARS', '2021-2024'),
                    "highlights": os.getenv('CV_EXP1_HIGHLIGHTS', 'Sistemas IA empresariales para 50k+ usuarios')
                },
                {
                    "company": os.getenv('CV_EXP2_COMPANY', 'IBM Collaborative Projects'),
                    "role": os.getenv('CV_EXP2_ROLE', 'AI Solutions Architect'),
                    "years": os.getenv('CV_EXP2_YEARS', '2017-2022'),
                    "highlights": os.getenv('CV_EXP2_HIGHLIGHTS', 'Liderazgo de proyectos IA con Watson')
                }
            ],
            "projects": [
                {
                    "name": os.getenv('CV_PROJ1_NAME', 'Enterprise AI Assistant Ecosystem'),
                    "tech": os.getenv('CV_PROJ1_TECH', 'LangGraph + CrewAI + Multiple LLMs'),
                    "description": os.getenv('CV_PROJ1_DESC', 'Sistema completo de asistentes IA empresariales')
                },
                {
                    "name": os.getenv('CV_PROJ2_NAME', 'AI-Powered Hydroelectric Platform'),
                    "tech": os.getenv('CV_PROJ2_TECH', 'Python + TensorFlow + BigQuery'),
                    "description": os.getenv('CV_PROJ2_DESC', 'Plataforma ML para predicci√≥n energ√≠a')
                }
            ]
        }
    
    def setup_ai(self):
        """Configurar IA con CrewAI - Sintaxis 2025 corregida"""
        try:
            print("üß† CONFIGURANDO IA...")
            
            if not DEEPSEEK_API_KEY:
                print("‚ùå DEEPSEEK_API_KEY falta")
                return
            
            # Configurar variables de entorno para OpenAI compatible
            os.environ["OPENAI_API_KEY"] = DEEPSEEK_API_KEY
            os.environ["OPENAI_API_BASE"] = DEEPSEEK_BASE_URL
            
            self.use_ai = True
            print("üéØ IA CONFIGURADA")
            
        except Exception as e:
            print(f"üí• Error setup_ai: {e}")
            self.use_ai = False
    
    async def process_query(self, message: str) -> str:
        """Procesa consulta usando CrewAI"""
        print(f"üîç Procesando: '{message}' - IA habilitada: {self.use_ai}")
        
        if self.use_ai:
            try:
                return await self.ai_response(message)
            except Exception as e:
                print(f"üí• ERROR CON IA: {e}")
                import traceback
                traceback.print_exc()
                return self.fallback_response(message)
        
        return self.simple_response(message)
    
    async def ai_response(self, message: str) -> str:
        """Respuesta usando CrewAI - Sintaxis 2025 verificada"""
        try:
            # Importar CrewAI con sintaxis correcta
            from crewai import Agent, Task, Crew, Process
            
            # Configurar LLM usando el patr√≥n actualizado
            try:
                from langchain_openai import ChatOpenAI
                llm = ChatOpenAI(
                    model="deepseek-chat",
                    base_url=DEEPSEEK_BASE_URL,
                    api_key=DEEPSEEK_API_KEY,
                    temperature=0.7
                )
            except ImportError:
                # Fallback si no est√° disponible langchain_openai
                print("‚ö†Ô∏è langchain_openai no disponible, usando configuraci√≥n b√°sica")
                llm = None
            
            # Crear agente con sintaxis 2025
            agent = Agent(
                role="AI Expert & Tech Consultant",
                goal="Provide helpful, professional information about AI and technology",
                backstory=f"""You are {self.cv_data['name']}, a {self.cv_data['title']} 
                based in {self.cv_data['location']}.
                
                Your expertise includes: {', '.join(self.cv_data['skills'])}
                
                Current role: {self.cv_data['experience'][0]['role']} at {self.cv_data['experience'][0]['company']}
                
                You are knowledgeable, helpful, and professional. Always provide accurate information
                about AI, technology, and your professional background.""",
                verbose=True,
                allow_delegation=False,
                llm=llm  # Puede ser None y CrewAI usar√° el default
            )
            
            # Crear tarea con sintaxis 2025
            task = Task(
                description=f"""Respond to this user query: "{message}"
                
                Provide a helpful, professional response based on your expertise in AI and technology.
                Be conversational but informative. If asked about your background, use the information
                from your backstory.""",
                expected_output="A helpful, professional response to the user's query",
                agent=agent
            )
            
            # Crear y ejecutar crew con sintaxis 2025
            crew = Crew(
                agents=[agent],
                tasks=[task],
                process=Process.sequential,  # Expl√≠citamente especificar proceso
                verbose=True
            )
            
            # Ejecutar crew
            result = crew.kickoff()
            
            # Extraer resultado seg√∫n la versi√≥n de CrewAI
            if hasattr(result, 'raw'):
                return str(result.raw)
            else:
                return str(result)
            
        except ImportError as e:
            print(f"‚ùå CrewAI no disponible: {e}")
            raise Exception("CrewAI no est√° instalado correctamente")
        except Exception as e:
            print(f"‚ùå Error en AI response: {e}")
            raise
    
    def fallback_response(self, message: str) -> str:
        """Respuesta fallback inteligente usando datos del CV"""
        msg_lower = message.lower()
        
        # Respuestas espec√≠ficas sobre IA
        if any(word in msg_lower for word in ['ai', 'inteligencia artificial', 'machine learning', 'crewai', 'langgraph']):
            return f"""üß† **Mi experiencia en IA:**

Como {self.cv_data['title']}, trabajo con tecnolog√≠as de vanguardia:

**üõ†Ô∏è Stack tecnol√≥gico:**
‚Ä¢ **Frameworks IA:** LangGraph, CrewAI, LangChain
‚Ä¢ **APIs LLM:** OpenAI, Claude, DeepSeek
‚Ä¢ **ML/DL:** TensorFlow, PyTorch, Scikit-learn
‚Ä¢ **Cloud:** AWS, Azure, Google Cloud

**üöÄ Proyecto destacado:**
*{self.cv_data['projects'][0]['name']}*
üîß Tech Stack: {self.cv_data['projects'][0]['tech']}
üìã {self.cv_data['projects'][0]['description']}

**üíº Experiencia actual:**
{self.cv_data['experience'][0]['role']} en {self.cv_data['experience'][0]['company']}
üèÜ {self.cv_data['experience'][0]['highlights']}

¬øHay algo espec√≠fico sobre IA que te interese conocer?"""
        
        # Respuesta sobre DeepSeek espec√≠ficamente
        if 'deepseek' in msg_lower:
            return f"""ü§ñ **Experiencia con DeepSeek:**

Como {self.cv_data['title']}, he trabajado con varios LLMs incluyendo DeepSeek:

**üîß Integraci√≥n t√©cnica:**
‚Ä¢ API integration con CrewAI
‚Ä¢ Optimizaci√≥n de prompts
‚Ä¢ Configuraci√≥n multi-modelo
‚Ä¢ Cost optimization strategies

**üí° Ventajas de DeepSeek:**
‚Ä¢ Excelente relaci√≥n calidad/precio
‚Ä¢ Soporte para APIs OpenAI-compatible
‚Ä¢ Rendimiento competitivo en tareas de c√≥digo

¬øTe interesa implementar DeepSeek en tu proyecto?"""
        
        return self.simple_response(message)
    
    def simple_response(self, message: str) -> str:
        """Respuestas b√°sicas sin IA - mejoradas"""
        msg_lower = message.lower()
        
        if any(word in msg_lower for word in ['hola', 'hello', 'hi', 'hey']):
            return f"""üëã **¬°Hola! Soy {self.cv_data['name']}**

*{self.cv_data['bio']}*

üéØ **Especializaci√≥n:**
‚Ä¢ Sistemas IA empresariales y multi-agente
‚Ä¢ Arquitectura de datos y MLOps
‚Ä¢ Integraci√≥n de LLMs y automatizaci√≥n

üõ†Ô∏è **Tech Stack actual:**
{', '.join(self.cv_data['skills'][:8])}

üìç {self.cv_data['location']}
‚ö° {self.cv_data['availability']}

**¬øEn qu√© puedo ayudarte hoy?**"""

        elif any(word in msg_lower for word in ['experiencia', 'skills', 'tecnolog√≠a', 'trabajo']):
            return f"""üíº **Mi trayectoria profesional:**

**üöÄ Rol actual:**
{self.cv_data['experience'][0]['role']} en *{self.cv_data['experience'][0]['company']}* ({self.cv_data['experience'][0]['years']})

üèÜ **Logros destacados:**
{self.cv_data['experience'][0]['highlights']}

**üìö Experiencia previa:**
{self.cv_data['experience'][1]['role']} en *{self.cv_data['experience'][1]['company']}*
üéØ {self.cv_data['experience'][1]['highlights']}

**üõ†Ô∏è Stack tecnol√≥gico:**
{', '.join(self.cv_data['skills'])}

¬øHay alguna tecnolog√≠a espec√≠fica que te interese?"""

        elif any(word in msg_lower for word in ['proyecto', 'portfolio', 'casos']):
            projects_text = "\n\n".join([
                f"**{i+1}. {proj['name']}**\nüõ†Ô∏è *Tech:* {proj['tech']}\nüìã {proj['description']}"
                for i, proj in enumerate(self.cv_data['projects'])
            ])
            
            return f"""üöÄ **Proyectos destacados:**

{projects_text}

**üìä Impacto cuantificado:**
‚Ä¢ Sistemas que procesan 1M+ transacciones/d√≠a
‚Ä¢ Plataformas que sirven a 50k+ usuarios activos
‚Ä¢ Reducci√≥n de costos operativos del 40%
‚Ä¢ Mejora en tiempo de respuesta del 60%

¬øTe interesa conocer detalles t√©cnicos de alg√∫n proyecto?"""

        elif any(word in msg_lower for word in ['disponible', 'contratar', 'contacto', 'colaborar']):
            return f"""üìÖ **Disponibilidad y colaboraci√≥n:**

‚ö° **Estado actual:** {self.cv_data['availability']}

**üéØ Servicios que ofrezco:**
‚Ä¢ ü§ñ Desarrollo de sistemas IA multi-agente
‚Ä¢ üîó Integraci√≥n de LLMs (GPT, Claude, DeepSeek)
‚Ä¢ üèóÔ∏è Arquitectura de datos y MLOps
‚Ä¢ üí° Consultor√≠a en transformaci√≥n digital IA

**üìã Para iniciar colaboraci√≥n, comp√°rteme:**
‚Ä¢ üìß Tu email de contacto
‚Ä¢ üè¢ Empresa/proyecto
‚Ä¢ üéØ Descripci√≥n del desaf√≠o t√©cnico
‚Ä¢ ‚ö° Tecnolog√≠as involucradas
‚Ä¢ üìÖ Timeline esperado

**‚è±Ô∏è Garant√≠a: Respuesta en menos de 24 horas**

¬øEn qu√© proyecto est√°s trabajando?"""

        elif any(word in msg_lower for word in ['precio', 'coste', 'tarifa', 'presupuesto']):
            return f"""üí∞ **Estructura de colaboraci√≥n:**

Como {self.cv_data['title']}, ofrezco diferentes modalidades:

**üéØ Consultor√≠a estrat√©gica:**
‚Ä¢ Auditor√≠a de arquitectura IA
‚Ä¢ Roadmap tecnol√≥gico
‚Ä¢ Due diligence t√©cnico

**üõ†Ô∏è Desarrollo t√©cnico:**
‚Ä¢ Implementaci√≥n de sistemas IA
‚Ä¢ Integraci√≥n de LLMs
‚Ä¢ MLOps y automatizaci√≥n

**üìã Para presupuesto personalizado:**
‚Ä¢ Describe el scope del proyecto
‚Ä¢ Timeline y urgencia
‚Ä¢ Recursos t√©cnicos disponibles
‚Ä¢ Complejidad estimada

Cada proyecto es √∫nico - prefiero discutir detalles antes de dar cifras.

¬øCu√°l es tu proyecto espec√≠fico?"""

        else:
            return f"""ü§ñ **Soy {self.cv_data['name']}**
*{self.cv_data['title']}*

**üß† Experto en:**
‚Ä¢ Inteligencia Artificial y Machine Learning
‚Ä¢ Sistemas multi-agente (CrewAI, LangGraph)
‚Ä¢ Arquitectura de datos enterprise
‚Ä¢ Integraci√≥n de LLMs y automatizaci√≥n

**üí¨ Puedes preguntarme sobre:**
‚Ä¢ üîß Experiencia t√©cnica y proyectos
‚Ä¢ üöÄ Tecnolog√≠as de IA y mejores pr√°cticas
‚Ä¢ üìÖ Disponibilidad para colaboraciones
‚Ä¢ üí° Soluciones espec√≠ficas a tus desaf√≠os

**¬øQu√© aspecto espec√≠fico te interesa explorar?**"""


class TelegramBot:
    """ü§ñ Bot de Telegram optimizado"""
    
    def __init__(self):
        print("ü§ñ Inicializando bot...")
        
        if not TELEGRAM_TOKEN:
            print("‚ùå TELEGRAM_TOKEN requerido")
            exit(1)
            
        self.digital_twin = SimpleDigitalTwin()
        self.app = Application.builder().token(TELEGRAM_TOKEN).build()
        self.setup_handlers()
        print("‚úÖ Bot inicializado")
    
    def setup_handlers(self):
        """Configurar handlers del bot"""
        self.app.add_handler(CommandHandler("start", self.start_command))
        self.app.add_handler(CommandHandler("help", self.help_command))
        self.app.add_handler(CommandHandler("about", self.about_command))
        self.app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, self.handle_message))
    
    async def start_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Comando start mejorado"""
        cv = self.digital_twin.cv_data
        
        welcome = f"""üöÄ **¬°Bienvenido al Digital Twin de {cv['name']}!**

*{cv['bio']}*

üìç **Ubicaci√≥n:** {cv['location']}
üíº **Rol actual:** {cv['title']}
‚ö° **Estado:** {cv['availability']}

**üéØ Soy especialista en:**
‚Ä¢ Sistemas IA empresariales y multi-agente
‚Ä¢ LangGraph, CrewAI, integraci√≥n de LLMs
‚Ä¢ Arquitectura de datos y MLOps

**üí¨ Comandos disponibles:**
‚Ä¢ `/help` - Ver todas las opciones
‚Ä¢ `/about` - Conocer mi experiencia detallada

**¬°Preg√∫ntame cualquier cosa sobre IA y tecnolog√≠a!** ü§ñ"""
        
        await update.message.reply_text(welcome, parse_mode='Markdown')
    
    async def help_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Comando help mejorado"""
        help_text = """üìã **¬øC√≥mo puedo ayudarte?**

**üîç Temas de consulta:**
‚Ä¢ üíª **Experiencia t√©cnica** - Skills, proyectos, tecnolog√≠as
‚Ä¢ üß† **Inteligencia Artificial** - CrewAI, LangGraph, LLMs
‚Ä¢ üöÄ **Casos de uso** - Proyectos reales, implementaciones
‚Ä¢ üìÖ **Colaboraci√≥n** - Disponibilidad, servicios, presupuestos
‚Ä¢ üéØ **Soluciones espec√≠ficas** - Tu desaf√≠o t√©cnico particular

**üí° Ejemplos de preguntas:**
‚Ä¢ "¬øQu√© experiencia tienes con CrewAI?"
‚Ä¢ "¬øC√≥mo integrar√≠as DeepSeek en un sistema empresarial?"
‚Ä¢ "Cu√©ntame sobre tus proyectos de IA"
‚Ä¢ "¬øEst√°s disponible para consultor√≠a?"

**ü§ñ ¬°Solo escribe tu pregunta en lenguaje natural!**"""
        
        await update.message.reply_text(help_text, parse_mode='Markdown')
    
    async def about_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Comando about con informaci√≥n detallada"""
        cv = self.digital_twin.cv_data
        
        about_text = f"""üë®‚Äçüíª **{cv['name']}**
*{cv['title']}*

**üè¢ Experiencia profesional:**

**üöÄ Actual:** {cv['experience'][0]['role']}
üìç {cv['experience'][0]['company']} ({cv['experience'][0]['years']})
üèÜ {cv['experience'][0]['highlights']}

**üìö Anterior:** {cv['experience'][1]['role']}
üìç {cv['experience'][1]['company']} ({cv['experience'][1]['years']})
üéØ {cv['experience'][1]['highlights']}

**üõ†Ô∏è Stack tecnol√≥gico:**
{', '.join(cv['skills'])}

**üí° Enfoque:**
Especializado en democratizar la IA empresarial mediante sistemas multi-agente inteligentes y arquitecturas escalables.

¬øQuieres conocer alg√∫n aspecto espec√≠fico?"""
        
        await update.message.reply_text(about_text, parse_mode='Markdown')
    
    async def handle_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Maneja mensajes de texto con mejor UX"""
        try:
            # Mostrar typing indicator
            await context.bot.send_chat_action(
                chat_id=update.effective_chat.id, 
                action="typing"
            )
            
            # Procesar mensaje
            response = await self.digital_twin.process_query(update.message.text)
            
            # Dividir respuesta si es muy larga
            if len(response) > 4096:
                # Telegram tiene l√≠mite de 4096 caracteres
                parts = [response[i:i+4000] for i in range(0, len(response), 4000)]
                for part in parts:
                    await update.message.reply_text(part, parse_mode='Markdown')
            else:
                await update.message.reply_text(response, parse_mode='Markdown')
            
            # Log para debug
            user = update.effective_user
            print(f"üë§ {user.first_name} ({user.id}): {update.message.text[:100]}...")
            print(f"ü§ñ Respuesta enviada ({len(response)} chars)")
            
        except Exception as e:
            logger.error(f"Error handling message: {e}")
            
            # Mensaje de error amigable
            error_msg = """ü§ñ Disculpa, encontr√© un problema t√©cnico.

**¬øPuedes intentar:**
‚Ä¢ Reformular tu pregunta
‚Ä¢ Usar `/help` para ver opciones
‚Ä¢ Contactar directamente si es urgente

*Estoy trabajando para solucionarlo.* üîß"""
            
            await update.message.reply_text(error_msg, parse_mode='Markdown')
    
    async def cleanup_webhook(self):
        """Limpia webhooks previos"""
        try:
            print("üßπ Limpiando conexiones previas...")
            await self.app.bot.delete_webhook(drop_pending_updates=True)
            await asyncio.sleep(2)
            print("‚úÖ Conexiones limpiadas")
        except Exception as e:
            print(f"‚ö†Ô∏è Error limpiando conexiones: {e}")
    
    def start_bot(self):
        """Inicia el bot con manejo robusto de errores"""
        try:
            print("üöÄ INICIANDO TELEGRAM BOT...")
            
            # Limpiar conexiones previas
            asyncio.run(self.cleanup_webhook())
            
            # Iniciar polling con configuraci√≥n optimizada
            print("üîÑ Iniciando polling...")
            self.app.run_polling(
                drop_pending_updates=True,
                timeout=30,
                poll_interval=1.0,
                bootstrap_retries=5
            )
            
        except KeyboardInterrupt:
            print("üëã Bot detenido por usuario")
        except Exception as e:
            logger.error(f"Error cr√≠tico en bot: {e}")
            import traceback
            traceback.print_exc()
            raise


if __name__ == "__main__":
    print("üöÄ INICIANDO DIGITAL TWIN BOT...")
    
    try:
        bot = TelegramBot()
        bot.start_bot()
    except Exception as e:
        print(f"‚ùå Error fatal: {e}")
        print("\nüí° Verifica:")
        print("‚Ä¢ TELEGRAM_TOKEN configurado")
        print("‚Ä¢ Dependencias instaladas: pip install python-telegram-bot crewai")
        print("‚Ä¢ Python >= 3.10")
        exit(1)